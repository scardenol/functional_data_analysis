set.seed(31)
iterations <- 100
# Synthetic Data
N <- 100  # rows or curves
P <- 1e2 # cols or time
grid <- seq(-1, 1, length.out = P)
grid2 <- seq(-2, 2, length.out = P)
grid3 <- seq(-0.5, 0.5, length.out = P)
C1 <- exp_cov_function(grid, alpha = 0.2, beta = 0.3)
C2 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.6)
C3 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.9)
centerline1 <- (grid)^2-1
centerline2 <- (grid)^2
centerline3 <- (grid)^2+1
# data_folds <- vfold_cv(data, v=iterations, repeats = 1)
# Clustering
method <- "euclidean"
minpts_search <- 2:100
K <- 2:4 # number of clusters to try
for (x in 1:iterations) {
print(paste("Iteration", x))
tryCatch({
#####  Defining Synthetic Data #####
# sample <- analysis(get_rsplit(data_folds, index = x))
m <- generate_gauss_fdata(N, centerline1, C1)
p <- generate_gauss_fdata(N, centerline2, C2)
q <- generate_gauss_fdata(N, centerline3, C3)
data <- rbind(m,p,q)
# Convert to functional data
fd <- fdata(sample)
# # Plot
# # m data
# plot(fd1, col="#0072B2")
# # p data
# lines(fd2, col="#D55E00")
# # Add a legend to the plot
# legend("topleft", legend=c("Data 1", "Data 2"),
#        col=c("#0072B2", "#D55E00"), lty = 1, cex=0.8)
# Experimentation
# 0. Run hdbscan_multiple_minPts to find the optimal minPts parameter
opt_minpts_df <- hdbscan_multiple_minPts(fd, minPts = minpts_search, method = method)
# Compute the optimal minPts parameter
opt_idx <- which.max(opt_minpts_df$mean_cluster_scores)
opt_minpts <- opt_minpts_df$minPts[opt_idx]
# 1. Density-based clustering with HDBSCAN
hdbscan_res <- hdbscan_fd(fd, minPts = opt_minpts, method = method)
# 2. Distance-based clustering with: custom pam, k-means (Manhattan), k-means (Euclidean)
k_hdbscan <- length(unique(hdbscan_res$cluster)) # number of clusters from hdbscan
distance_res <- distance_based_clustering(fd, K = K, verbose = "minimal")
# Format results into a data frame
results_df <- results_to_df(distance_res, K = K)
results_df$iteration <- x # add iteration
# Store results
# Hacer un data frame para avg_membership_prob, avg_outlier_scores
res_hdbscan <- rbind(res_hdbscan,
data.frame(
avg_score = mean(hdbscan_res$cluster_scores),
iteration = x
))
res_distance <- rbind(res_distance, results_df)
},
error=function(e){
cat("ERROR:", conditionMessage(e), "\n")
print("Attempting next iteration...")
}
)
}
# Visualize results: time, connectivity, dunn and silhouette
# p_time <- plot_distance_results(results_df, result_type = "time")
# p_connectivity <- plot_distance_results(results_df, result_type = "connectivity")
# p_dunn <- plot_distance_results(results_df, result_type = "dunn")
# p_silhouette <- plot_distance_results(results_df, result_type = "silhouette")
# Extract silhouette diagram for each method from the results
# p_silhouette_kmeans <- distance_res$kmeans_res$diagram
# p_silhouette_pam <- distance_res$pam_res$diagram
# p_silhouette_kmeans_man <- distance_res$kmeans_man_res$diagram
# Boxplot
theme_set(theme_grey())
# Muestra de una iteraciÃ³n, falta generalizar
prob_stability <- data.frame(membership_prob=hdbscan_res$membership_prob,
k=hdbscan_res$cluster)
# Clear environment
rm(list = ls())
# Set working directory to wherever the script is
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load custom modules
source("modules/library_manager/library_manager.R")
source("modules/preprocessing/preprocessing.R")
source("modules/visualization/visualization.R")
source("modules/numerical/numerical.R")
source("modules/clustering/clustering.R")
source("modules/write_data/write_data.R")
# List all packages to install/load
packages <- c(
"readxl", # To read the excel input files
"tidyr",
"plyr",
"dplyr",
"fda.usc", # Main functional data library
"cluster", # Pam, Silhouette, Connectivity, Dunn
"caret",
"scales", # Opacity in plots
"ggplot2", # Main static plot library
"plotly", # Main dynamic plot library
"factoextra", # Silhoutte diagram
"clValid", # Connectivity and Dunn
"dbscan", # HDBSCAN algorithm
"DepthProc", # Functional boxplot fncBoxPlot
"reshape2", # To use melt
"LambertW",
"latex2exp",
"reshape2",
"rgl",
"htmltools",
"roahd",
"data.table",
"rsample"
)
# Load or Install and Load packages
load_packages(packages)
# Check if packages loaded
loaded_packages <- data.frame(
Packages = packages,
Loaded = packages %in% loadedNamespaces()
)
loaded_packages
# Create an empty list to store results
res_hdbscan <- data.frame(
avg_score = numeric(0),
iteration = numeric(0)
)
res_distance <- data.frame()
# Experiment parameters
# Seed. 31
set.seed(31)
iterations <- 100
# Synthetic Data
N <- 100  # rows or curves
P <- 1e2 # cols or time
grid <- seq(-1, 1, length.out = P)
grid2 <- seq(-2, 2, length.out = P)
grid3 <- seq(-0.5, 0.5, length.out = P)
C1 <- exp_cov_function(grid, alpha = 0.2, beta = 0.3)
C2 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.6)
C3 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.9)
centerline1 <- (grid)^2-1
centerline2 <- (grid)^2
centerline3 <- (grid)^2+1
# data_folds <- vfold_cv(data, v=iterations, repeats = 1)
# Clustering
method <- "euclidean"
minpts_search <- 2:100
K <- 2:4 # number of clusters to try
for (x in 1:iterations) {
print(paste("Iteration", x))
tryCatch({
#####  Defining Synthetic Data #####
# sample <- analysis(get_rsplit(data_folds, index = x))
m <- generate_gauss_fdata(N, centerline1, C1)
p <- generate_gauss_fdata(N, centerline2, C2)
q <- generate_gauss_fdata(N, centerline3, C3)
data <- rbind(m,p,q)
# Convert to functional data
fd <- fdata(sample)
# # Plot
# # m data
# plot(fd1, col="#0072B2")
# # p data
# lines(fd2, col="#D55E00")
# # Add a legend to the plot
# legend("topleft", legend=c("Data 1", "Data 2"),
#        col=c("#0072B2", "#D55E00"), lty = 1, cex=0.8)
# Experimentation
# 0. Run hdbscan_multiple_minPts to find the optimal minPts parameter
opt_minpts_df <- hdbscan_multiple_minPts(fd, minPts = minpts_search, method = method)
# Compute the optimal minPts parameter
opt_idx <- which.max(opt_minpts_df$mean_cluster_scores)
opt_minpts <- opt_minpts_df$minPts[opt_idx]
# 1. Density-based clustering with HDBSCAN
hdbscan_res <- hdbscan_fd(fd, minPts = opt_minpts, method = method)
# 2. Distance-based clustering with: custom pam, k-means (Manhattan), k-means (Euclidean)
k_hdbscan <- length(unique(hdbscan_res$cluster)) # number of clusters from hdbscan
distance_res <- distance_based_clustering(fd, K = K, verbose = "minimal")
# Format results into a data frame
results_df <- results_to_df(distance_res, K = K)
results_df$iteration <- x # add iteration
# Store results
# Hacer un data frame para avg_membership_prob, avg_outlier_scores
res_hdbscan <- rbind(res_hdbscan,
data.frame(
avg_score = mean(hdbscan_res$cluster_scores),
iteration = x
))
res_distance <- rbind(res_distance, results_df)
},
error=function(e){
cat("ERROR:", conditionMessage(e), "\n")
print("Attempting next iteration...")
}
)
}
# Visualize results: time, connectivity, dunn and silhouette
# p_time <- plot_distance_results(results_df, result_type = "time")
# p_connectivity <- plot_distance_results(results_df, result_type = "connectivity")
# p_dunn <- plot_distance_results(results_df, result_type = "dunn")
# p_silhouette <- plot_distance_results(results_df, result_type = "silhouette")
# Extract silhouette diagram for each method from the results
# p_silhouette_kmeans <- distance_res$kmeans_res$diagram
# p_silhouette_pam <- distance_res$pam_res$diagram
# p_silhouette_kmeans_man <- distance_res$kmeans_man_res$diagram
# Boxplot
theme_set(theme_grey())
# Muestra de una iteraciÃ³n, falta generalizar
prob_stability <- data.frame(membership_prob=hdbscan_res$membership_prob,
k=hdbscan_res$cluster)
# Clear environment
rm(list = ls())
# Set working directory to wherever the script is
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load custom modules
source("modules/library_manager/library_manager.R")
source("modules/preprocessing/preprocessing.R")
source("modules/visualization/visualization.R")
source("modules/numerical/numerical.R")
source("modules/clustering/clustering.R")
source("modules/write_data/write_data.R")
# List all packages to install/load
packages <- c(
"readxl", # To read the excel input files
"tidyr",
"plyr",
"dplyr",
"fda.usc", # Main functional data library
"cluster", # Pam, Silhouette, Connectivity, Dunn
"caret",
"scales", # Opacity in plots
"ggplot2", # Main static plot library
"plotly", # Main dynamic plot library
"factoextra", # Silhoutte diagram
"clValid", # Connectivity and Dunn
"dbscan", # HDBSCAN algorithm
"DepthProc", # Functional boxplot fncBoxPlot
"reshape2", # To use melt
"LambertW",
"latex2exp",
"reshape2",
"rgl",
"htmltools",
"roahd",
"data.table",
"rsample"
)
# Load or Install and Load packages
load_packages(packages)
# Check if packages loaded
loaded_packages <- data.frame(
Packages = packages,
Loaded = packages %in% loadedNamespaces()
)
loaded_packages
# Create an empty list to store results
res_hdbscan <- data.frame(
avg_score = numeric(0),
iteration = numeric(0)
)
res_distance <- data.frame()
# Experiment parameters
# Seed. 31
set.seed(31)
iterations <- 1
# Synthetic Data
N <- 100  # rows or curves
P <- 1e2 # cols or time
grid <- seq(-1, 1, length.out = P)
grid2 <- seq(-2, 2, length.out = P)
grid3 <- seq(-0.5, 0.5, length.out = P)
C1 <- exp_cov_function(grid, alpha = 0.2, beta = 0.3)
C2 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.6)
C3 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.9)
centerline1 <- (grid)^2-1
centerline2 <- (grid)^2
centerline3 <- (grid)^2+1
# data_folds <- vfold_cv(data, v=iterations, repeats = 1)
# Clustering
method <- "euclidean"
minpts_search <- 2:100
K <- 2:4 # number of clusters to try
for (x in 1:iterations) {
print(paste("Iteration", x))
tryCatch({
#####  Defining Synthetic Data #####
# sample <- analysis(get_rsplit(data_folds, index = x))
m <- generate_gauss_fdata(N, centerline1, C1)
p <- generate_gauss_fdata(N, centerline2, C2)
q <- generate_gauss_fdata(N, centerline3, C3)
data <- rbind(m,p,q)
# Convert to functional data
fd <- fdata(sample)
# # Plot
# # m data
# plot(fd1, col="#0072B2")
# # p data
# lines(fd2, col="#D55E00")
# # Add a legend to the plot
# legend("topleft", legend=c("Data 1", "Data 2"),
#        col=c("#0072B2", "#D55E00"), lty = 1, cex=0.8)
# Experimentation
# 0. Run hdbscan_multiple_minPts to find the optimal minPts parameter
opt_minpts_df <- hdbscan_multiple_minPts(fd, minPts = minpts_search, method = method)
# Compute the optimal minPts parameter
opt_idx <- which.max(opt_minpts_df$mean_cluster_scores)
opt_minpts <- opt_minpts_df$minPts[opt_idx]
# 1. Density-based clustering with HDBSCAN
hdbscan_res <- hdbscan_fd(fd, minPts = opt_minpts, method = method)
# 2. Distance-based clustering with: custom pam, k-means (Manhattan), k-means (Euclidean)
k_hdbscan <- length(unique(hdbscan_res$cluster)) # number of clusters from hdbscan
distance_res <- distance_based_clustering(fd, K = K, verbose = "minimal")
# Format results into a data frame
results_df <- results_to_df(distance_res, K = K)
results_df$iteration <- x # add iteration
# Store results
# Hacer un data frame para avg_membership_prob, avg_outlier_scores
res_hdbscan <- rbind(res_hdbscan,
data.frame(
avg_score = mean(hdbscan_res$cluster_scores),
iteration = x
))
res_distance <- rbind(res_distance, results_df)
},
error=function(e){
cat("ERROR:", conditionMessage(e), "\n")
print("Attempting next iteration...")
}
)
}
# Clear environment
rm(list = ls())
# Set working directory to wherever the script is
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load custom modules
source("modules/library_manager/library_manager.R")
source("modules/preprocessing/preprocessing.R")
source("modules/visualization/visualization.R")
source("modules/numerical/numerical.R")
source("modules/clustering/clustering.R")
source("modules/write_data/write_data.R")
# List all packages to install/load
packages <- c(
"readxl", # To read the excel input files
"tidyr",
"plyr",
"dplyr",
"fda.usc", # Main functional data library
"cluster", # Pam, Silhouette, Connectivity, Dunn
"caret",
"scales", # Opacity in plots
"ggplot2", # Main static plot library
"plotly", # Main dynamic plot library
"factoextra", # Silhoutte diagram
"clValid", # Connectivity and Dunn
"dbscan", # HDBSCAN algorithm
"DepthProc", # Functional boxplot fncBoxPlot
"reshape2", # To use melt
"LambertW",
"latex2exp",
"reshape2",
"rgl",
"htmltools",
"roahd",
"data.table",
"rsample"
)
# Load or Install and Load packages
load_packages(packages)
# Check if packages loaded
loaded_packages <- data.frame(
Packages = packages,
Loaded = packages %in% loadedNamespaces()
)
loaded_packages
# Create an empty list to store results
res_hdbscan <- data.frame(
avg_score = numeric(0),
iteration = numeric(0)
)
res_distance <- data.frame()
# Experiment parameters
# Seed. 31
set.seed(31)
iterations <- 1
# Synthetic Data
N <- 100  # rows or curves
P <- 1e2 # cols or time
grid <- seq(-1, 1, length.out = P)
grid2 <- seq(-2, 2, length.out = P)
grid3 <- seq(-0.5, 0.5, length.out = P)
C1 <- exp_cov_function(grid, alpha = 0.2, beta = 0.3)
C2 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.6)
C3 <- exp_cov_function(grid2, alpha = 0.2, beta = 0.9)
centerline1 <- (grid)^2-1
centerline2 <- (grid)^2
centerline3 <- (grid)^2+1
# data_folds <- vfold_cv(data, v=iterations, repeats = 1)
# Clustering
method <- "euclidean"
minpts_search <- 2:100
K <- 2:4 # number of clusters to try
for (x in 1:iterations) {
print(paste("Iteration", x))
tryCatch({
#####  Defining Synthetic Data #####
# sample <- analysis(get_rsplit(data_folds, index = x))
m <- generate_gauss_fdata(N, centerline1, C1)
p <- generate_gauss_fdata(N, centerline2, C2)
q <- generate_gauss_fdata(N, centerline3, C3)
data <- rbind(m,p,q)
# Convert to functional data
fd <- fdata(sample)
# # Plot
# # m data
# plot(fd1, col="#0072B2")
# # p data
# lines(fd2, col="#D55E00")
# # Add a legend to the plot
# legend("topleft", legend=c("Data 1", "Data 2"),
#        col=c("#0072B2", "#D55E00"), lty = 1, cex=0.8)
# Experimentation
# 0. Run hdbscan_multiple_minPts to find the optimal minPts parameter
opt_minpts_df <- hdbscan_multiple_minPts(fd, minPts = minpts_search, method = method)
# Compute the optimal minPts parameter
opt_idx <- which.max(opt_minpts_df$mean_cluster_scores)
opt_minpts <- opt_minpts_df$minPts[opt_idx]
# 1. Density-based clustering with HDBSCAN
hdbscan_res <- hdbscan_fd(fd, minPts = opt_minpts, method = method)
# 2. Distance-based clustering with: custom pam, k-means (Manhattan), k-means (Euclidean)
k_hdbscan <- length(unique(hdbscan_res$cluster)) # number of clusters from hdbscan
distance_res <- distance_based_clustering(fd, K = K, verbose = "minimal")
# Format results into a data frame
results_df <- results_to_df(distance_res, K = K)
results_df$iteration <- x # add iteration
# Store results
# Hacer un data frame para avg_membership_prob, avg_outlier_scores
res_hdbscan <- rbind(res_hdbscan,
data.frame(
avg_score = mean(hdbscan_res$cluster_scores),
iteration = x
))
res_distance <- rbind(res_distance, results_df)
},
error=function(e){
cat("ERROR:", conditionMessage(e), "\n")
print("Attempting next iteration...")
}
)
}
# Store results
# Hacer un data frame para avg_membership_prob, avg_outlier_scores
res_hdbscan <- rbind(res_hdbscan,
data.frame(
avg_score = mean(hdbscan_res$cluster_scores),
iteration = x
))
res_distance <- rbind(res_distance, results_df)
tryCatch({
#####  Defining Synthetic Data #####
# sample <- analysis(get_rsplit(data_folds, index = x))
m <- generate_gauss_fdata(N, centerline1, C1)
p <- generate_gauss_fdata(N, centerline2, C2)
q <- generate_gauss_fdata(N, centerline3, C3)
data <- rbind(m,p,q)
# Convert to functional data
fd <- fdata(sample)
# # Plot
# # m data
# plot(fd1, col="#0072B2")
# # p data
# lines(fd2, col="#D55E00")
# # Add a legend to the plot
# legend("topleft", legend=c("Data 1", "Data 2"),
#        col=c("#0072B2", "#D55E00"), lty = 1, cex=0.8)
# Experimentation
# 0. Run hdbscan_multiple_minPts to find the optimal minPts parameter
opt_minpts_df <- hdbscan_multiple_minPts(fd, minPts = minpts_search, method = method)
# Compute the optimal minPts parameter
opt_idx <- which.max(opt_minpts_df$mean_cluster_scores)
opt_minpts <- opt_minpts_df$minPts[opt_idx]
# 1. Density-based clustering with HDBSCAN
hdbscan_res <- hdbscan_fd(fd, minPts = opt_minpts, method = method)
# 2. Distance-based clustering with: custom pam, k-means (Manhattan), k-means (Euclidean)
k_hdbscan <- length(unique(hdbscan_res$cluster)) # number of clusters from hdbscan
distance_res <- distance_based_clustering(fd, K = K, verbose = "minimal")
# Format results into a data frame
results_df <- results_to_df(distance_res, K = K)
results_df$iteration <- x # add iteration
# Store results
# Hacer un data frame para avg_membership_prob, avg_outlier_scores
res_hdbscan <- rbind(res_hdbscan,
data.frame(
avg_score = mean(hdbscan_res$cluster_scores),
iteration = x
))
res_distance <- rbind(res_distance, results_df)
},
error=function(e){
cat("ERROR:", conditionMessage(e), "\n")
print("Attempting next iteration...")
}
)
# Clear environment
rm(list = ls())
# Set working directory to wherever the script is
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
