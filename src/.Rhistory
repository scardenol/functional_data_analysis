x = "Number of clusters k",
y = "Time (s)",
title = "Time for each method"
)
barplot(df)
hist(df)
ggplot(df, aes(x=cluster)) +
geom_bar(stat = "identity", position = "dodge") +
theme_bw() +
labs(
x = "Number of clusters k",
y = "Time (s)",
title = "Time for each method"
)
ggplot(df, aes(x=rownames, y=cluster)) +
geom_bar(stat = "identity", position = "dodge") +
theme_bw() +
labs(
x = "Number of clusters k",
y = "Time (s)",
title = "Time for each method"
)
library(ggplot2, quietly = TRUE)
df <- data.frame(c(496), c(136), c(157), c(246), c(352), c(423))
colnames(df) <- as.character(seq(1:6))
df <- t(df)
colnames(df) <- "count"
df$cluster <- rownames(df)
df
rownames(df)
library(ggplot2, quietly = TRUE)
df <- data.frame(c(496), c(136), c(157), c(246), c(352), c(423))
colnames(df) <- as.character(seq(1:6))
df <- t(df)
colnames(df) <- "count"
df
rownames(df)
df$cluster <- row.names(df)
library(dplyr, quietly = TRUE)
library(ggplot2, quietly = TRUE)
library(dplyr, quietly = TRUE)
df <- data.frame(c(496), c(136), c(157), c(246), c(352), c(423))
colnames(df) <- as.character(seq(1:6))
df <- t(df)
colnames(df) <- "count"
df <- tibble::rownames_to_column(df, "cluster")
df
is.data.frame(df)
as.data.frame(df)
is.data.frame(as.data.frame(df))
df <- as.data.frame(df)
df <- tibble::rownames_to_column(df, "cluster")
ggplot(df, aes(x=cluster, y=count)) +
geom_bar(stat = "identity", position = "dodge") +
theme_bw() +
labs(
x = "Number of clusters k",
y = "Time (s)",
title = "Time for each method"
)
ggplot(df, aes(x=cluster, y=count, fill=cluster)) +
geom_bar(stat = "identity", position = "dodge") +
theme_bw() +
labs(
x = "Number of clusters k",
y = "Time (s)",
title = "Time for each method"
)
ggplot(df, aes(x=cluster, y=count, fill=cluster)) +
geom_bar(stat = "identity", position = "dodge") +
theme_bw() +
labs(
x = "",
y = "Count",
title = "HDBSCAN - Number of curves per cluster"
)
library(readxl, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(plyr, quietly = TRUE)
library(dplyr, quietly = TRUE)
library(fda.usc, quietly = TRUE)
library(cluster, quietly = TRUE)
library(caret, quietly = TRUE)
library(scales, quietly = TRUE) # Opacity
library(ggplot2, quietly = TRUE)
library(plotly, quietly = TRUE)
library(factoextra, quietly=TRUE) # Silhoutte diagram
library(clValid, quietly = TRUE) # Connectivity and Dunn
library(dbscan, quietly = TRUE) # For HDBSCAN
library(DepthProc, quietly = TRUE) # For functional boxplot fncBoxPlot
library(reshape2, quietly = TRUE) # To use melt
# Clear environment
rm(list = ls())
# Set working directory to wherever the script is
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load functions from scripts
if (!exists("plot_clusters", mode = "function")) {
source("functions/plot_clusters.R")
}
if (!exists("reorder_labels", mode = "function")) {
source("functions/reorder_labels.R")
}
if (!exists("validation_indexes", mode = "function")) {
source("functions/validation_indexes.R")
}
if (!exists("mat2fun", mode = "function")) {
source("functions/mat2fun.R")
}
if (!exists("pam_fd", mode = "function")) {
source("functions/pam_fd.R")
}
if (!exists("norm_indicators", mode = "function")) {
source("functions/norm_indicators.R")
}
# load data from users (skip first 2 columns: id_record)
# Think about reading this in a loop, maybe store them in a list and create the name
# of each item
user1 <- read_excel(path = "data/id_service_3144.xlsx", range = cell_cols("C:F"))
user2 <- read_excel(path = "data/id_service_3237.xlsx", range = cell_cols("C:F"))
user3 <- read_excel(path = "data/id_service_3260.xlsx", range = cell_cols("C:F"))
user4 <- read_excel(path = "data/id_service_3262.xlsx", range = cell_cols("C:F"))
user5 <- read_excel(path = "data/id_service_3285.xlsx", range = cell_cols("C:F"))
user6 <- read_excel(path = "data/id_service_3287.xlsx", range = cell_cols("C:F"))
user7 <- read_excel(path = "data/id_service_3302.xlsx", range = cell_cols("C:F"))
user8 <- read_excel(path = "data/id_service_3305.xlsx", range = cell_cols("C:F"))
user9 <- read_excel(path = "data/id_service_3314.xlsx", range = cell_cols("C:F"))
user10 <- read_excel(path = "data/id_service_3325.xlsx", range = cell_cols("C:F"))
# convert to data frame
# Loop this
user1 <- as.data.frame(user1)
user2 <- as.data.frame(user2)
user3 <- as.data.frame(user3)
user4 <- as.data.frame(user4)
user5 <- as.data.frame(user5)
user6 <- as.data.frame(user6)
user7 <- as.data.frame(user7)
user8 <- as.data.frame(user8)
user9 <- as.data.frame(user9)
user10 <- as.data.frame(user10)
# check column types
# Loop this, maybe check if the same columns are there for every user
# throw error else
sapply(user1, mode)
sapply(user2, mode)
sapply(user3, mode)
sapply(user4, mode)
sapply(user5, mode)
sapply(user6, mode)
sapply(user7, mode)
sapply(user8, mode)
sapply(user9, mode)
sapply(user10, mode)
# Check dimensions of each user's data
dim(user1)
dim(user2)
dim(user3)
dim(user4)
dim(user5)
dim(user6)
dim(user7)
dim(user8)
dim(user9)
dim(user10)
# Create a simple preprocessing function that takes the data and: drops the r_value column,
# separates the timestamp column into date and time columns, and separates the time column into hour column
preprocess <- function(data, timestamp_col = "record_timestamp", drop_col = "name") {
# drop r_value column for now
drop_idx <- grep(drop_col, colnames(data))
data <- data[, -drop_idx]
# separate timestamp column "enertstamp" into "date" and "time" columns
data <- separate(data, timestamp_col, c("date", "time"), sep = " ")
# Supress possible warning from separate
defaultW <- getOption("warn")
options(warn = -1)
# Separate "time" column into "hour" column
data <- separate(data, "time", c("hour"), sep = ":")
# Restore warning option
options(warn = defaultW)
return(data)
}
# Preprocess each user's data
user1 <- preprocess(user1)
user2 <- preprocess(user2)
user3 <- preprocess(user3)
user4 <- preprocess(user4)
user5 <- preprocess(user5)
user6 <- preprocess(user6)
user7 <- preprocess(user7)
user8 <- preprocess(user8)
user9 <- preprocess(user9)
user10 <- preprocess(user10)
# Check how many complete days of data we have for each user vs the
# total amount of days
# Create a function to check this
check_days <- function(user, user_name_col = "id_service") {
# Extract the user name from the provided column
user_name <- user[user_name_col][1,]
# Create table for the dates
user_table <- table(user$date)
# Sum the number of times the records cover an entire day (24-hour records)
complete_days <- sum(user_table == 24)
# Sum the total number recorded of days (whole or not)
days <- length(table(user$date))
# Return the results as a data frame to be append multiple results
return(as.data.frame(list(
"user" = user_name,
"num_24h_days" = complete_days,
"total_days" = days
)))
}
# Take all users, apply the check_days function and rbind the results
days_df <- do.call(rbind, lapply(list(user1, user2, user3, user4, user5,
user6, user7, user8, user9, user10),
check_days))
days_df
# Find the user with the least number of 24-hour recorder days
min_days_df <- days_df[which.min(days_df[,2]),]
min_days_df
# Check how many complete days of data match for all users vs
# the total amount of days
# Users have different lengths, so we filter by user6 the user with least amount of
# days
# extract dates from user 6 to filter
user_dates <- names(table(user6$date))
matching_dates_table <- table(user1$date)[user_dates] == 24 &
table(user2$date)[user_dates] == 24 &
table(user3$date)[user_dates] == 24 &
table(user4$date)[user_dates] == 24 &
table(user5$date)[user_dates] == 24 &
table(user6$date)[user_dates] == 24 &
table(user7$date)[user_dates] == 24 &
table(user8$date)[user_dates] == 24 &
table(user9$date)[user_dates] == 24 &
table(user10$date)[user_dates] == 24
# Count the number of days where user have matching dates for 24-hour records
table(matching_dates_table == TRUE)
# Get the dates that match for all users
matching_dates <-
names(matching_dates_table[matching_dates_table == TRUE])
# Filter every user by the dates that match for all users
user1 <- user1 %>% filter(date %in% matching_dates)
user2 <- user2 %>% filter(date %in% matching_dates)
user3 <- user3 %>% filter(date %in% matching_dates)
user4 <- user4 %>% filter(date %in% matching_dates)
user5 <- user5 %>% filter(date %in% matching_dates)
user6 <- user6 %>% filter(date %in% matching_dates)
user7 <- user7 %>% filter(date %in% matching_dates)
user8 <- user8 %>% filter(date %in% matching_dates)
user9 <- user9 %>% filter(date %in% matching_dates)
user10 <- user10 %>% filter(date %in% matching_dates)
# Create function to convert data into an fdata object with its labels
data_to_fd <- function(data, id_col = "id_service") {
# Initialize variables
curves <- c()
clusters <- c()
col_names <- unique(data$hour)
dates <- c()
i <- 1
for (current_date in unique(data$date)) {
# Filter data by current date
data_by_date <- data %>% filter(date == current_date)
# Get current user (cluster)
current_user <- unique(data_by_date[id_col])
# Store the value vector as the current curve
curve <- t(data_by_date$value)
# Set column names
colnames(curve) <- col_names
# Store the value for the curve in the curves matrix, fill with NA if there
# are missing hours
curves <- rbind.fill(
as.data.frame(curves),
as.data.frame(curve)
)
# Store date of current curve in the dates vector
dates <- rbind(dates, unique(data_by_date$date))
# Store the current user in a cluster vector
clusters <- rbind(clusters, c(current_user))
i <- i + 1
}
# Create fdata object arguments
argvals <- 1:ncol(curves)
rangeval <- c(head(argvals, 1), tail(argvals, 1))
main <- "Daily Energy consumption on 2022"
xlab <- "Hour"
ylab <- "Active energy (kWh)"
names <- list(
main = main,
xlab = xlab,
ylab = ylab
)
# Convert to fdata
fun_data <-
fdata(
mdata = curves,
argvals = argvals,
rangeval = rangeval,
names = names
)
# Return fdata object and labels
return(list(fun_data = fun_data, cluster = clusters))
}
# Convert each user's data to an fdata object with its labels
user1_results <- data_to_fd(user1)
user2_results <- data_to_fd(user2)
user3_results <- data_to_fd(user3)
user4_results <- data_to_fd(user4)
user5_results <- data_to_fd(user5)
user6_results <- data_to_fd(user6)
user7_results <- data_to_fd(user7)
user8_results <- data_to_fd(user8)
user9_results <- data_to_fd(user9)
user10_results <- data_to_fd(user10)
# Pack the results into a list
user_results <-
list(
user1_results,
user2_results,
user3_results,
user4_results,
user5_results,
user6_results,
user7_results,
user8_results,
user9_results,
user10_results
)
# Create a function to bind a list of fdata objects into a single fdata object and
# a list of labels into a single vector of labels
bind_fd <- function(user_results) {
# Initialize variables
data <- c()
clusters <- c()
# Iterate through each user's resulting list of (fdata, cluster)
for (user in user_results) {
# Extract the fdata and cluster from the list
user_fd <- user$fun_data
user_cluster <- user$cluster
# Bind the data from the fdata object to the data matrix
data <- rbind(data, user_fd$data)
# Bind the cluster to the clusters vector
clusters <- rbind(clusters, user_cluster)
}
# Create fdata object arguments
# The arguments are the same for every user, so we can just use the first user's
# fdata object
argvals <- user_results[[1]]$fun_data$argvals
rangeval <- user_results[[1]]$fun_data$rangeval
names <- user_results[[1]]$fun_data$names
# Convert to fdata
fun_data <-
fdata(
mdata = data,
argvals = argvals,
rangeval = rangeval,
names = names
)
# Create a vector of users as the current clusters
users <- clusters
# Convert the clusters to numeric integer sequence starting from 1
clusters <- as.numeric(as.factor(unlist(clusters)))
# Return fdata object and labels
return(list(
fun_data = fun_data,
cluster = clusters,
users = users
))
}
# Bind all users' data into a single fdata object and a single vector of labels
binded_users <- bind_fd(user_results)
# Extract the fdata object and labels from the list
fun_data <- binded_users$fun_data
labels <- binded_users$cluster
users <- binded_users$users
# Plot all users raw
fun_df <- rbind(user1, user2, user3, user4, user5, user6, user7, user8, user9, user10)
fun_df <- as_tibble(fun_df)
p <- fun_df %>%
ggplot(aes(
x = hour,
y = value,
group = as.factor(date),
col = as.factor(id_service)
)) +
geom_line(alpha = 0.3) +
theme_bw() +
labs(
colour = "User id_service",
x = "Hour",
y = "Active energy (kWh)",
title = "Daily Energy consumption on 2022"
)
ggplotly(p)
# Function to print the cluster size and average silhouette width for each cluster
# Takes a silhouette class object and prints the results
print_summary <- function(sil_object) {
# Summary of the silhouette object
summary_results <- summary(sil_object)
# Store the cluster size and average width results as a single array
main_results <- t(rbind(cluster_size=summary_results$clus.sizes,
avg_silhouette_width=summary_results$clus.avg.widths))
# Create the cluster column and convert to data frame as a side effect
main_results <- tibble::rowid_to_column(as.data.frame(main_results), "cluster")
# Return the results
return(main_results)
}
# ---------------------------------------------------------------------------------------------------------------------
# -----------------------------------------EXPERIMENT------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------------------
# Experiment on functional PAM and functional k-means on original data
# General settings
# Set random seed for reproducible experimentation
set.seed(1)
# 0) Compute distance matrix and visualize histogram for clues of separation
# Distance matrices
dist_mat <- dist(fun_data$data, method = "euclidean")
dist_mat_man <- dist(fun_data$data, method = "manhattan")
hist(dist_mat, main = "Euclidean distance histogram", breaks = 70)
hist(dist_mat_man, main = "Manhattan distance histogram", breaks = 70)
# 1) Density-based clustering to determine the optimal number of clusters k
# HDBSCAN
cols <- ncol(fun_data$data)
# Takes the data and minPts = columns + 1
db <- hdbscan(fun_data$data, minPts = cols + 1)
db$cluster <- db$cluster+1 # Make cluster labels start from 1
db
# Visualize resulting clusters
db_p <- fun_df %>%
ggplot(aes(
x = hour,
y = value,
group = as.factor(date),
col = as.factor(rep(db$cluster, each = cols))
)) +
geom_line(alpha = 0.3) +
theme_bw() +
labs(
colour = "HDBSCAN clusters",
x = "Hour",
y = "Active energy (kWh)",
title = "Daily Energy consumption on 2022"
)
ggplotly(db_p)
# Further analysis per cluster
db_pl <- list()
for (c in sort(unique(db$cluster))) {
method <- "MBD"
db_pl[[c]] <- fncBoxPlot(fun_data$data[which(db$cluster %in% c),],
bands = c(0, 0.5, 0.75, 1),
method = method) +
ggtitle(fun_data$names$main,
subtitle = paste0("Cluster ", c, ", Depth Method ", method, sep ="")) +
labs(x = fun_data$names$xlab, y = fun_data$names$ylab)
}
db_pl[[1]]
db_pl[[2]]
db_pl[[3]]
db_pl2 <- list()
for (c in sort(unique(db$cluster))) {
method <- "FM"
db_pl2[[c]] <- fncBoxPlot(fun_data$data[which(db$cluster %in% c),],
bands = c(0, 0.5, 0.75, 1),
method = method) +
ggtitle(fun_data$names$main,
subtitle = paste0("Cluster ", c, ", Depth Method ", method, sep ="")) +
labs(x = fun_data$names$xlab, y = fun_data$names$ylab)
}
db_pl2[[1]]
db_pl2[[2]]
db_pl2[[3]]
# Clear environment
rm(list = ls())
# Set working directory to wherever the script is
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load custom modules
source("modules/library_manager/library_manager.R")
source("modules/read_data/read_data.R")
source("modules/preprocessing/preprocessing.R")
source("modules/visualization/visualization.R")
source("modules/numerical/numerical.R")
source("modules/clustering/clustering.R")
source("modules/write_data/write_data.R")
# List all packages to install/load
packages <- c(
"readxl", # To read the excel input files
"tidyr",
"plyr",
"dplyr",
"fda.usc", # Main functional data library
"cluster", # Pam, Silhouette, Connectivity, Dunn
"caret",
"scales", # Opacity in plots
"ggplot2", # Main static plot library
"plotly", # Main dynamic plot library
"factoextra", # Silhoutte diagram
"clValid", # Connectivity and Dunn
"dbscan", # HDBSCAN algorithm
"DepthProc", # Functional boxplot fncBoxPlot
"reshape2", # To use melt
"LambertW",
"latex2exp",
"reshape2",
"rgl",
"htmltools"
)
# Load or Install and Load packages
load_packages(packages)
# Check if packages loaded
loaded_packages <- data.frame(
Packages = packages,
Loaded = packages %in% loadedNamespaces()
)
loaded_packages
